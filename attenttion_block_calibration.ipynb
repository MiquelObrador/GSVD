{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e324994b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mobrrei/miniconda3/envs/svd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  7.85it/s]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset from cache/wikitext2_64_2048_42_dict.pt\n",
      "Calibration data loaded.\n",
      "model.layers.3.mlp.gate_proj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting activations for model.layers.3.mlp.gate_proj: 100%|██████████| 16/16 [00:15<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying GSVD to model.layers.3.mlp.gate_proj with low rank: 2178\n",
      "Training GSVD layer for model.layers.3.mlp.gate_proj...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training GSVD layer for model.layers.3.mlp.gate_proj. Loss: 0.059030828066170216\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from utils import (replace_module_by_name, get_calib_train_data,\n",
    "                   get_truncate)\n",
    "from modules import SVDLinearLayer, HybridLoss\n",
    "from tqdm import tqdm\n",
    "import gc # --- CHANGE: Import garbage collector\n",
    "\n",
    "RATIO = 0.6\n",
    "CALIB_DATASET = \"wikitext2\"\n",
    "model_name = \"huggyllama/llama-7b\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "SEQLEN = model.config.max_position_embeddings\n",
    "BATCH_SIZE = 4\n",
    "CALIB_SAMPLES = 64\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "calib_data = get_calib_train_data(name=CALIB_DATASET,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  seqlen=SEQLEN,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  nsamples=CALIB_SAMPLES,\n",
    "                                  seed=SEED)\n",
    "print(\"Calibration data loaded.\")\n",
    "\n",
    "GRADIENT_EPOCHS = 30\n",
    "CALIB_BATCH_SIZE = 8\n",
    "GRADS_PATH = None  # Path to the CSV file containing gradient importance weights, or None if not used\n",
    "activation_fn = nn.SiLU()\n",
    "grads = {}\n",
    "\n",
    "linear_layer_names = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear) and name != \"lm_head\":\n",
    "        linear_layer_names.append(name)\n",
    "\n",
    "target_layers = [\n",
    "    \"model.layers.3.mlp.gate_proj\"]\n",
    "\n",
    "for name in reversed(linear_layer_names):\n",
    "    if name in target_layers:\n",
    "        print(name)\n",
    "            \n",
    "        activations = []\n",
    "        def forward_hook(module, input, output):\n",
    "            activations.append(input[0].detach().cpu())\n",
    "\n",
    "        hook = module.register_forward_hook(forward_hook)\n",
    "        model.eval()\n",
    "        model.half()\n",
    "        model.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(calib_data, desc=f\"Getting activations for {name}\"):\n",
    "                input_ids = batch['input_ids'].to(DEVICE)\n",
    "                attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "                model(input_ids=input_ids, attention_mask=attention_mask, use_cache=False)\n",
    "        hook.remove()\n",
    "\n",
    "        # --- CHANGE: Aggressively clear VRAM after activation gathering ---\n",
    "        model.to('cpu')\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        activations = torch.cat(activations, dim=0).float()\n",
    "\n",
    "        module.to(DEVICE).float()\n",
    "\n",
    "        W = module.weight.data.clone().detach().to(DEVICE)\n",
    "        b = module.bias.data.clone().detach().to(DEVICE) if module.bias is not None else None\n",
    "\n",
    "        out_features, in_features = W.shape\n",
    "        low_rank = get_truncate(in_features, out_features, RATIO)\n",
    "        print(f\"Applying GSVD to {name} with low rank: {low_rank}\")\n",
    "\n",
    "        U, S, VT = torch.linalg.svd(W, full_matrices=False)\n",
    "        s_sqrt = torch.diag(torch.sqrt(S))\n",
    "        u_parameter = torch.matmul(U[:, :low_rank], s_sqrt[:low_rank, :low_rank])\n",
    "        vt_parameter = torch.matmul(s_sqrt[:low_rank, :low_rank], VT[:low_rank, :])\n",
    "\n",
    "        svd_layer = SVDLinearLayer(\n",
    "            vt_parameter=vt_parameter,\n",
    "            u_parameter=u_parameter,\n",
    "            bias=b,\n",
    "        )\n",
    "        svd_layer.to(DEVICE).train()\n",
    "        \n",
    "        # If the layer is a mlp.gate_proj let's calibrate it with the activation function to ensure a more accurate representation\n",
    "        if 'mlp.gate_proj' in name:\n",
    "            activation = activation_fn\n",
    "        else:\n",
    "            activation = nn.Identity()\n",
    "\n",
    "        del W, U, S, VT, s_sqrt, u_parameter, vt_parameter, b\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        importance_weights = grads[name] if GRADS_PATH is not None else None\n",
    "        #Ensure no 0 importance weights are passed, if they are, use a threshold of 0.01\n",
    "        if importance_weights is not None:\n",
    "            importance_weights = torch.where(importance_weights < 0.01, torch.tensor(0.01, device=importance_weights.device), importance_weights)\n",
    "\n",
    "        loss_fn = HybridLoss(weights=importance_weights,\n",
    "                            alpha=0.5,  # Adjust alpha as needed\n",
    "                            reduction=\"mean\").to(DEVICE)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(svd_layer.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "\n",
    "        print(f\"Training GSVD layer for {name}...\")\n",
    "        activation_dataset = torch.utils.data.TensorDataset(activations)\n",
    "        activation_loader = torch.utils.data.DataLoader(\n",
    "            activation_dataset,\n",
    "            batch_size=CALIB_BATCH_SIZE,\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        loss_log = []\n",
    "        # Initial loss before training\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0.0\n",
    "            for batch_tuple in activation_loader:\n",
    "                batch = batch_tuple[0].to(DEVICE)\n",
    "                output = activation(svd_layer(batch))\n",
    "                target = activation(module(batch))\n",
    "                loss = loss_fn(output, target)\n",
    "                total_loss += loss.item() * batch.size(0)\n",
    "            initial_loss = total_loss / len(activation_dataset)\n",
    "            loss_log.append(initial_loss)\n",
    "        \n",
    "        for epoch in range(GRADIENT_EPOCHS):\n",
    "            epoch_loss_log = []\n",
    "            pbar = tqdm(activation_loader, desc=f\"Epoch {epoch+1}/{GRADIENT_EPOCHS}\", leave=False)\n",
    "\n",
    "            for batch_tuple in pbar:\n",
    "                batch = batch_tuple[0].to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                output = activation(svd_layer(batch))\n",
    "                # The target needs to be computed on the GPU with the original module\n",
    "                with torch.no_grad():\n",
    "                    target = activation(module(batch))\n",
    "                loss = loss_fn(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss_log.append(loss.item())\n",
    "                pbar.set_postfix({'loss': loss.item()})\n",
    "            loss_log.append(sum(epoch_loss_log) / len(epoch_loss_log))\n",
    "\n",
    "        print(f\"Finished training GSVD layer for {name}. Loss: {loss_log[-1]}\")\n",
    "        \n",
    "        svd_layer.to('cpu').eval().half()\n",
    "        replace_module_by_name(model, name, svd_layer)\n",
    "        \n",
    "        # --- CHANGE: Clean up and save checkpoint ---\n",
    "        del svd_layer, activations, loss_fn, optimizer, module\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Plot loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(0, GRADIENT_EPOCHS + 1), loss_log, marker='o')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f51f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mobrrei/miniconda3/envs/svd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  7.75it/s]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dataset from cache/wikitext2_10_2048_42_dict.pt\n",
      "Calibration data loaded.\n",
      "Target modules for attention: ['model.layers.3.self_attn']\n",
      "Processing module: model.layers.3.self_attn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting activations for model.layers.3.self_attn:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(calib_data, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting activations for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;66;03m# We just need to run the forward pass to trigger the hook\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m              \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m              \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m hook\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m     84\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:842\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 842\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    857\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:594\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    583\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    584\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m         position_embeddings,\n\u001b[1;32m    592\u001b[0m     )\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 594\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:336\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/torch/nn/modules/module.py:1857\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1859\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/svd/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1780\u001b[0m     \u001b[38;5;241m*\u001b[39m_global_forward_pre_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1782\u001b[0m ):\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks_with_kwargs:\n\u001b[0;32m-> 1784\u001b[0m         args_kwargs_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m args_kwargs_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1786\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_kwargs_result, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args_kwargs_result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "Cell \u001b[0;32mIn[1], line 70\u001b[0m, in \u001b[0;36mforward_pre_hook\u001b[0;34m(module, args, kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m activations\u001b[38;5;241m.\u001b[39mappend(kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_states\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Capture the corresponding attention mask\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m attention_masks\u001b[38;5;241m.\u001b[39mappend(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args, kwargs\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from utils import (replace_module_by_name, get_calib_train_data,\n",
    "                   get_truncate)\n",
    "from modules import SVDLinearLayer, HybridLoss\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Your existing setup code ---\n",
    "RATIO = 0.6\n",
    "CALIB_DATASET = \"wikitext2\"\n",
    "model_name = \"huggyllama/llama-7b\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "SEQLEN = model.config.max_position_embeddings\n",
    "BATCH_SIZE = 4\n",
    "CALIB_SAMPLES = 10\n",
    "SEED = 42\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "calib_data = get_calib_train_data(name=CALIB_DATASET,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  seqlen=SEQLEN,\n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  nsamples=CALIB_SAMPLES,\n",
    "                                  seed=SEED)\n",
    "print(\"Calibration data loaded.\")\n",
    "\n",
    "GRADIENT_EPOCHS = 30\n",
    "CALIB_BATCH_SIZE = 8\n",
    "GRADS_PATH = None\n",
    "activation_fn = nn.SiLU()\n",
    "grads = {}\n",
    "\n",
    "target_modules = [\n",
    "    \"model.layers.3.self_attn\"\n",
    "]\n",
    "\n",
    "modules_names = []\n",
    "for name, module in model.named_modules():\n",
    "    if name in target_modules:\n",
    "        modules_names.append(name)\n",
    "\n",
    "def get_module_linear_layers(module):\n",
    "    linear_layers = {}\n",
    "    for name, sub_module in module.named_modules():\n",
    "        if isinstance(sub_module, nn.Linear):\n",
    "            linear_layers[name] = sub_module\n",
    "    return linear_layers\n",
    "\n",
    "print(\"Target modules for attention:\", modules_names)\n",
    "\n",
    "# --- Start of the new calibration logic ---\n",
    "\n",
    "for name in reversed(modules_names):\n",
    "    original_module = dict(model.named_modules())[name]\n",
    "    print(f\"Processing module: {name}\")\n",
    "\n",
    "    # 1. CAPTURE INPUT ACTIVATIONS AND ATTENTION MASKS\n",
    "    activations = []\n",
    "    attention_masks = [] # We need masks for the forward pass\n",
    "\n",
    "    def forward_pre_hook(module, args, kwargs):\n",
    "        activations.append(kwargs['hidden_states'].detach().cpu())\n",
    "        # Capture the corresponding attention mask\n",
    "        attention_masks.append(kwargs['attention_mask'].detach().cpu())\n",
    "        return args, kwargs\n",
    "\n",
    "    hook = original_module.register_forward_pre_hook(forward_pre_hook, with_kwargs=True)\n",
    "    \n",
    "    model.eval().half().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(calib_data, desc=f\"Getting activations for {name}\"):\n",
    "            # We just need to run the forward pass to trigger the hook\n",
    "            model(input_ids=batch['input_ids'].to(DEVICE),\n",
    "                  attention_mask=batch['attention_mask'].to(DEVICE),\n",
    "                  use_cache=False)\n",
    "    hook.remove()\n",
    "\n",
    "    model.to('cpu')\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    activations = torch.cat(activations, dim=0).float()\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    print(f\"Captured activations shape: {activations.shape}\")\n",
    "    print(f\"Captured attention masks shape: {attention_masks.shape}\")\n",
    "\n",
    "    # 2. CREATE THE SVD-REPLACED MODULE\n",
    "    svd_module = copy.deepcopy(original_module)\n",
    "    linear_layers = get_module_linear_layers(svd_module)\n",
    "    print(f\"Found {len(linear_layers)} linear layers in {name} to replace.\")\n",
    "\n",
    "    for lname, lmodule in linear_layers.items():\n",
    "        W = lmodule.weight.data.clone()\n",
    "        b = lmodule.bias.data.clone() if lmodule.bias is not None else None\n",
    "\n",
    "        out_features, in_features = W.shape\n",
    "        low_rank = get_truncate(in_features, out_features, RATIO)\n",
    "        \n",
    "        U, S, VT = torch.linalg.svd(W, full_matrices=False)\n",
    "        s_sqrt = torch.diag(torch.sqrt(S))\n",
    "        u_parameter = (U[:, :low_rank] @ s_sqrt[:low_rank, :low_rank])\n",
    "        vt_parameter = (s_sqrt[:low_rank, :low_rank] @ VT[:low_rank, :])\n",
    "\n",
    "        svd_layer = SVDLinearLayer(\n",
    "            vt_parameter=vt_parameter,\n",
    "            u_parameter=u_parameter,\n",
    "            bias=b,\n",
    "        )\n",
    "        replace_module_by_name(svd_module, lname, svd_layer)\n",
    "        del W, U, S, VT, s_sqrt, u_parameter, vt_parameter, b, svd_layer\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # 3. SET UP FOR TRAINING\n",
    "    original_module.to(DEVICE).float().eval()\n",
    "    svd_module.to(DEVICE).float().train()\n",
    "\n",
    "    # The optimizer now takes all parameters from the SVD module\n",
    "    optimizer = torch.optim.AdamW(svd_module.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "    loss_fn = HybridLoss(reduction=\"mean\").to(DEVICE)\n",
    "\n",
    "    # The dataset now contains both activations and masks\n",
    "    activation_dataset = torch.utils.data.TensorDataset(activations, attention_masks)\n",
    "    activation_loader = torch.utils.data.DataLoader(\n",
    "        activation_dataset,\n",
    "        batch_size=CALIB_BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    loss_log = []\n",
    "    print(f\"Calibrating all layers in {name} simultaneously...\")\n",
    "\n",
    "    # 4. RUN THE CALIBRATION LOOP\n",
    "    for epoch in range(GRADIENT_EPOCHS):\n",
    "        epoch_loss = 0.0\n",
    "        pbar = tqdm(activation_loader, desc=f\"Epoch {epoch+1}/{GRADIENT_EPOCHS}\", leave=False)\n",
    "        for act_batch, mask_batch in pbar:\n",
    "            act_batch = act_batch.to(DEVICE)\n",
    "            mask_batch = mask_batch.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get output from the SVD module\n",
    "            # The output is a tuple (hidden_states, attn_weights, past_key_value)\n",
    "            svd_output = svd_module(hidden_states=act_batch, attention_mask=mask_batch)[0]\n",
    "\n",
    "            # Get target output from the original module\n",
    "            with torch.no_grad():\n",
    "                original_output = original_module(hidden_states=act_batch, attention_mask=mask_batch)[0]\n",
    "\n",
    "            loss = loss_fn(svd_output, original_output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        loss_log.append(epoch_loss / len(activation_loader))\n",
    "\n",
    "    print(f\"Finished calibrating {name}. Final Loss: {loss_log[-1]:.6f}\")\n",
    "\n",
    "    # 5. REPLACE THE ORIGINAL MODULE IN THE MAIN MODEL\n",
    "    svd_module.to('cpu').eval().half()\n",
    "    replace_module_by_name(model, name, svd_module)\n",
    "    \n",
    "    print(\"Module replaced in the main model.\")\n",
    "\n",
    "    # 6. CLEAN UP MEMORY\n",
    "    del original_module, svd_module, activations, attention_masks, loss_fn, optimizer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Plot loss curve for this module\n",
    "    plt.plot(range(1, GRADIENT_EPOCHS + 1), loss_log, marker='o')\n",
    "    plt.title(f'Calibration Loss Curve for {name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
