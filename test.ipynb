{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8d3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from einops import rearrange, einsum\n",
    "from torch.nn import functional as F\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c8fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11008, 18432)\n",
      "(4096, 11008)\n"
     ]
    }
   ],
   "source": [
    "pre_act = np.load('../Llama_7B/pre_act_layer31_mlp_down.npy')\n",
    "\n",
    "pre_act = pre_act.reshape(-1, pre_act.shape[-1]).T\n",
    "\n",
    "print(pre_act.shape)\n",
    "weights = np.load('../Llama_7B/weight_layer31_mlp_down.npy')\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca7977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the data into torch tensors\n",
    "pre_act = torch.from_numpy(pre_act).float().to(DEVICE)\n",
    "weights = torch.from_numpy(weights).float().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbac960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncating 1792 weights\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.6 # 60% of the weights\n",
    "out_features, in_features = weights.shape\n",
    "        \n",
    "if in_features == out_features:\n",
    "    truncate = math.ceil(ratio * in_features / 2)\n",
    "else:\n",
    "    truncate = math.ceil((ratio * in_features * out_features) / (in_features + out_features))\n",
    "    \n",
    "# truncate = math.ceil(min(in_features, out_features) * ratio)\n",
    "\n",
    "print(f\"Truncating {truncate} weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582bec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncating 1228 weights\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.6 # 60% of the weights\n",
    "out_features, in_features = weights.shape\n",
    "        \n",
    "if in_features == out_features:\n",
    "    truncate = int(ratio * in_features / 2)\n",
    "else:\n",
    "    truncate = int((ratio * in_features * out_features) / (in_features + out_features))\n",
    "    \n",
    "# truncate = math.ceil(min(in_features, out_features) * ratio)\n",
    "\n",
    "print(f\"Truncating {truncate} weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8cf05cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncating 1229 weights\n"
     ]
    }
   ],
   "source": [
    "from utils import get_truncate\n",
    "\n",
    "ratio = 0.6\n",
    "out_features, in_features = weights.shape\n",
    "\n",
    "truncate = get_truncate(in_features, out_features, ratio)\n",
    "print(f\"Truncating {truncate} weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7691e61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncating 1228 weights\n"
     ]
    }
   ],
   "source": [
    "ratio = 0.6 # 60% of the weights\n",
    "out_features, in_features = weights.shape\n",
    "        \n",
    "\n",
    "truncate = int((ratio * in_features * out_features) / (in_features + out_features))\n",
    "    \n",
    "# truncate = math.ceil(min(in_features, out_features) * ratio)\n",
    "\n",
    "print(f\"Truncating {truncate} weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48bdccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 18432])\n"
     ]
    }
   ],
   "source": [
    "act_real = torch.matmul(weights, pre_act)\n",
    "print(act_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eddb06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelScaling(nn.Module):\n",
    "    \"\"\"\n",
    "    Batch Normalization without mean and beta.\n",
    "    This is a custom implementation that normalizes the input by dividing by the standard deviation\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.register_buffer(\"running_var\", torch.ones(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_len, num_features)\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, seq_len, num_features)\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.training:\n",
    "            var = x.var(dim=(0, 1), unbiased=False)# Calculate variance over batch and sequence dimensions\n",
    "            self.running_var.data.copy_ = self.momentum * var + (1 - self.momentum) * self.running_var # Update running variance\n",
    "        else:\n",
    "            var = self.running_var # Use running variance during inference\n",
    "\n",
    "        x_norm = x / torch.sqrt(var.view(1, 1, -1) + self.eps) # Normalize the input by dividing by the standard deviation\n",
    "        return self.gamma.view(1, 1, -1) * x_norm  # Scale the normalized input by gamma\n",
    "        \n",
    "\n",
    "class SVDLinearLayer(nn.Module):\n",
    "    def __init__(self, weights, truncate, bias=None, data=None):\n",
    "        super(SVDLinearLayer, self).__init__()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        device = weights.device\n",
    "        \n",
    "        out_features, in_features = weights.shape\n",
    "        \n",
    "        if data.dim() == 2: # Add batch dimension if missing.\n",
    "            data = data.unsqueeze(0).to(device)\n",
    "            \n",
    "        self.normalization1 = ChannelScaling(weights.shape[1]).to(device)\n",
    "        data_var = data.var(dim=(0, 1), unbiased=False).to(device)\n",
    "        self.normalization1.running_var.data.copy_(data_var)\n",
    "        \n",
    "        # Compute normalization factors for the weights\n",
    "        diag_norm1 = torch.diag(self.normalization1.gamma / torch.sqrt(self.normalization1.running_var + self.normalization1.eps)).to(device)\n",
    "        \n",
    "        weights = torch.matmul(weights, torch.inverse(diag_norm1))\n",
    "        \n",
    "        # #Perform SVD on the weights\n",
    "        # U, S, Vt = torch.linalg.svd(weights, full_matrices=False)\n",
    "        # U = U[:, :truncate]\n",
    "        # S = S[:truncate]\n",
    "        # Vt = Vt[:truncate, :]\n",
    "        \n",
    "        U, S, V = torch.svd_lowrank(weights, q=truncate, niter=1)\n",
    "        Vt = V.t()\n",
    "        \n",
    "        diag_s = torch.diag(torch.sqrt(S))\n",
    "        \n",
    "        vt_parameter = torch.matmul(diag_s, Vt)\n",
    "        \n",
    "        self.vt_linear = nn.Linear(in_features, truncate, bias=False)\n",
    "        self.vt_linear.weight.data.copy_(vt_parameter)\n",
    "        \n",
    "        self.normalization2 = ChannelScaling(U.shape[1]).to(device)\n",
    "        \n",
    "        self.normalization1.eval()\n",
    "        data_var = F.linear(self.normalization1(data), vt_parameter, bias=None).var(dim=(0, 1), unbiased=False).to(device)\n",
    "        self.normalization1.train()\n",
    "        self.normalization2.running_var.data.copy_(data_var)\n",
    "        diag_norm2 = torch.diag(self.normalization2.gamma / torch.sqrt(self.normalization2.running_var + self.normalization2.eps)).to(device)\n",
    "        \n",
    "        u_parameter = torch.matmul(U, torch.matmul(diag_s, torch.inverse(diag_norm2)))\n",
    "            \n",
    "        self.bias = bias\n",
    "        \n",
    "        self.u_linear = nn.Linear(truncate, out_features, bias=True if bias is not None else False)\n",
    "        if bias is not None:\n",
    "            self.u_linear.bias.data.copy_(bias)\n",
    "        self.u_linear.weight.data.copy_(u_parameter)\n",
    "        \n",
    "        del weights, U, S, Vt, diag_s, diag_norm1, diag_norm2, data_var, data, device, u_parameter, vt_parameter\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_len, in_features) or (seq_len, in_features)\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, seq_len, out_features)\n",
    "        \"\"\"\n",
    "        \n",
    "        if x.dim() == 2: # Add batch dimension if missing.\n",
    "            x = x.unsqueeze(0)\n",
    "            \n",
    "        x = self.normalization1(x)\n",
    "        \n",
    "        x = self.vt_linear(x)\n",
    "        \n",
    "        x = self.normalization2(x) \n",
    "        \n",
    "        x = self.u_linear(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    \n",
    "    def reconstruct_weights(self):\n",
    "        \"\"\"\n",
    "        Reconstruct the effective weight matrix, taking into account the normalization layers.\n",
    "        \"\"\"\n",
    "        device = self.vt_linear.weight.device\n",
    "        \n",
    "        # Incorporate normalization factors from normalization1.\n",
    "        if isinstance(self.normalization1, ChannelScaling):\n",
    "            norm1 = self.normalization1\n",
    "            diag_norm1 = torch.diag(norm1.gamma / torch.sqrt(norm1.running_var + norm1.eps))\n",
    "        else:\n",
    "            diag_norm1 = torch.eye(self.vt_linear.weight.shape[1], device=device)\n",
    "            \n",
    "        # Incorporate normalization factors from normalization2.\n",
    "        if isinstance(self.normalization2, ChannelScaling):\n",
    "            norm2 = self.normalization2\n",
    "            diag_norm2 = torch.diag(norm2.gamma / torch.sqrt(norm2.running_var + norm2.eps))\n",
    "        else:\n",
    "            diag_norm2 = torch.eye(self.u_linear.weight.shape[1], device=device)\n",
    "        \n",
    "        # Reconstruct the weight matrix.\n",
    "        return self.u_linear.weight @ diag_norm2 @ self.vt_linear.weight @ diag_norm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0afa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_module = SVDLinearLayer(weights, truncate, None, pre_act.T).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "978cbc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:24<00:00,  5.93it/s, loss=1.77e+3]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "ITERS = 500\n",
    "losses = []\n",
    "new_module.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(new_module.parameters(), lr=0.0001)\n",
    "\n",
    "pbar = tqdm(range(ITERS))\n",
    "for i in pbar:\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    aprox_act = new_module(pre_act.T).squeeze().T\n",
    "    \n",
    "    loss = torch.norm(aprox_act - act_real, p='fro')\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    pbar.set_postfix({'loss': loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2478bf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1872.4783\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    new_module.eval()\n",
    "    aprox_act = new_module(pre_act.T).squeeze().T\n",
    "    print(\"loss: \", torch.norm(aprox_act - act_real, p='fro').detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd11673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVDLinearLayer(\n",
      "  (normalization1): ChannelScaling()\n",
      "  (vt_linear): Linear(in_features=11008, out_features=1792, bias=False)\n",
      "  (normalization2): ChannelScaling()\n",
      "  (u_linear): Linear(in_features=1792, out_features=4096, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(new_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89c5b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_module = SVDLinearLayer(weights, truncate, None, pre_act.T).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84088a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training vt_linear with normalization1: 100%|██████████| 500/500 [01:17<00:00,  6.47it/s, loss=2.82e+3]\n",
      "Training u_linear with normalization2: 100%|██████████| 500/500 [00:46<00:00, 10.67it/s, loss=2.04e+3]\n",
      "Training everything: 100%|██████████| 500/500 [01:24<00:00,  5.95it/s, loss=1.76e+3]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training vt_linear with normalization1\n",
    "new_module.train()\n",
    "for param in new_module.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in new_module.vt_linear.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in new_module.normalization1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, new_module.parameters()), lr=0.0001)\n",
    "losses = []\n",
    "\n",
    "pbar = tqdm(range(ITERS), desc=\"Training vt_linear with normalization1\")\n",
    "for i in pbar:\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    aprox_act = new_module(pre_act.T).squeeze().T\n",
    "    loss = torch.norm(aprox_act - act_real, p='fro')\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "# Training u_linear with normalization2\n",
    "new_module.train()\n",
    "for param in new_module.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in new_module.u_linear.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in new_module.normalization2.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, new_module.parameters()), lr=0.0001)\n",
    "\n",
    "pbar = tqdm(range(ITERS), desc=\"Training u_linear with normalization2\")\n",
    "for i in pbar:\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    aprox_act = new_module(pre_act.T).squeeze().T\n",
    "    loss = torch.norm(aprox_act - act_real, p='fro')\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "# Training everything together\n",
    "new_module.train()\n",
    "for param in new_module.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(new_module.parameters(), lr=0.0001)\n",
    "\n",
    "pbar = tqdm(range(ITERS), desc=\"Training everything\")\n",
    "for i in pbar:\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    aprox_act = new_module(pre_act.T).squeeze().T\n",
    "    loss = torch.norm(aprox_act - act_real, p='fro')\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_postfix({'loss': loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6378f6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1759.162\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    new_module.train()\n",
    "    aprox_act = new_module(pre_act.T).squeeze().T\n",
    "    print(\"loss: \", torch.norm(aprox_act - act_real, p='fro').detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4983495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncating 2389 weights for ratio 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:50<00:00,  9.94it/s, loss=1.25e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncating 1792 weights for ratio 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:38<00:00, 12.93it/s, loss=1.77e+3]\n"
     ]
    }
   ],
   "source": [
    "def get_ratios(final_ratio, matrix_iters):\n",
    "    ratios = []\n",
    "    for i in range(1, matrix_iters + 1):\n",
    "        r = 1 - i * (1 - final_ratio) / matrix_iters\n",
    "        ratios.append(r)\n",
    "    return ratios\n",
    "\n",
    "def get_truncate(in_features, out_features, ratio):\n",
    "    if in_features == out_features:\n",
    "        return math.ceil(ratio * in_features / 2)\n",
    "    else:\n",
    "        return math.ceil((ratio * in_features * out_features) / (in_features + out_features))\n",
    "\n",
    "GRADIENT_ITERS = 500\n",
    "MATRIX_ITERS = 2\n",
    "FINAL_RATIO = 0.6\n",
    "\n",
    "ratios = get_ratios(FINAL_RATIO, MATRIX_ITERS)\n",
    "\n",
    "new_weights = weights.clone()\n",
    "new_weights = new_weights.to(DEVICE)\n",
    "\n",
    "for ratio in ratios:\n",
    "    in_features, out_features = new_weights.shape\n",
    "    truncate = get_truncate(in_features, out_features, ratio)\n",
    "    \n",
    "    print(f\"Truncating {truncate} weights for ratio {ratio}\")\n",
    "    \n",
    "    new_module = SVDLinearLayer(new_weights, truncate, None, pre_act.T).to(DEVICE)\n",
    "    new_module.train()\n",
    "    optimizer = torch.optim.AdamW(new_module.parameters(), lr=0.0001)\n",
    "    \n",
    "    pbar = tqdm(range(GRADIENT_ITERS))\n",
    "    for i in pbar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        aprox_act = new_module(pre_act.T).squeeze().T\n",
    "\n",
    "        loss = torch.norm(aprox_act - act_real, p='fro')\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    new_module.eval()\n",
    "    with torch.no_grad():\n",
    "        new_weights = new_module.reconstruct_weights()\n",
    "        new_weights = new_weights.to(DEVICE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f81af1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1823.6628\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    new_module.eval()\n",
    "    aprox_act = new_module(pre_act.T).squeeze().T\n",
    "    print(\"loss: \", torch.norm(aprox_act - act_real, p='fro').detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ce6125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mobrrei/miniconda3/envs/svd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00, 10.14it/s]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "Replacing modules: 100%|██████████| 423/423 [00:20<00:00, 20.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping lm_head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (341469 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Evaluating: 100%|██████████| 21/21 [00:42<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 8.5546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from svdmodels import SVDModel\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from utils import load_wikitext\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"huggyllama/llama-7b\",torch_dtype=torch.float16)\n",
    "SEQ_LEN = model.config.max_position_embeddings\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"huggyllama/llama-7b\")\n",
    "model = SVDModel.load_model(model, ratio=0.8, model_path=\"results/llama-7b/gsvd_llama-7b_r0.8_g500_c256_m1.pt\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.half()\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    BATCH_SIZE = 8\n",
    "    \n",
    "    loader = load_wikitext(tokenizer,\n",
    "                           seq_len=SEQ_LEN,\n",
    "                            batch_size=BATCH_SIZE)\n",
    "    \n",
    "    nlls = []\n",
    "    for batch in tqdm(loader, desc=\"Evaluating\", total=len(loader)):\n",
    "        batch = batch.to(DEVICE)\n",
    "        logits = model(input_ids=batch, use_cache=False).logits\n",
    "        if torch.isfinite(logits).all():\n",
    "            shited_logits = logits[:, :-1, :].contiguous()\n",
    "            shifted_labels = batch[:, 1:].contiguous()\n",
    "            loss_fnc = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "            loss = loss_fnc(shited_logits.view(-1, logits.size(-1)), shifted_labels.view(-1))\n",
    "            nlls.append(loss.cpu())\n",
    "        else:\n",
    "            print(\"Non-finite logits detected, skipping batch.\")\n",
    "            continue\n",
    "        \n",
    "    mean_loss = torch.cat(nlls).mean()\n",
    "    ppl = torch.exp(mean_loss).item()\n",
    "    if ppl > 1000:\n",
    "        ppl = int(ppl)\n",
    "        \n",
    "    print(f\"Perplexity: {ppl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814d096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
